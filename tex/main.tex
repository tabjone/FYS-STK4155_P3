% {{{
\documentclass[a4paper,10pt,english]{article}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{graphicx, verbatim, amsmath, amsfonts, geometry, float, import, bm}
\usepackage{siunitx} % converts expression to SI units/notation , \num{10e-10}
\usepackage[hidelinks]{hyperref}
\usepackage{url}
\usepackage{biblatex}


\usepackage{algpseudocode}
\usepackage{algorithm}

% \bibliography{refs}

%Box around tex
\usepackage{mdframed}

%Subfigures
%\usepackage{caption, subcaption}
\usepackage{subfigure}        % imports a lot of cool and useful figure commands

\usepackage{gensymb}


% Code higligthing
\usepackage{listings}
\usepackage{xcolor}
\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}

\lstdefinestyle{mystyle}{
	commentstyle=\color{codegreen},
	keywordstyle=\color{magenta},
	stringstyle=\color{codepurple},
	basicstyle=\ttfamily\footnotesize,
	breakatwhitespace=false,         
	breaklines=true,                 
	captionpos=b,                    
	keepspaces=true,                 
	numbersep=5pt,                  
	showspaces=false,                
	showstringspaces=false,
	showtabs=false,                  
	tabsize=4
}
\lstset{style=mystyle}
\setlength{\parindent}{0mm}
\setlength{\parskip}{1.5mm}

% }}}

\title{Exploring advantages/disadvantages of solving PDEs with Neural Networks}
\author{Tor-Andreas Bjone}

\begin{document}
\maketitle
\tableofcontents

\input{./abstract.tex}
\input{./introduction.tex}
\input{./methods.tex}
\input{./results.tex}
\input{./conclusion.tex}


\section*{References}  
\begin{itemize}
\bibitem[1]{1} Tveito, A. \& Winther, R. (2005) Introduction to Partial Differential Equations: A computational approach. 2nd edn. New York, NY, USA: Springer.

\bibitem[2]{2} Humfeld, K \& Zobeiry, N. (2020)  Physics-Informed Machine Learning Approach for Solving Heat Transfer Equation
    in Advanced Manufacturing and Engineering Applications. Washington, Seattle, WA: University of Washington
\end{itemize}



\begin{figure}
\centering
\subfigure[Rms, ReLu]{\label{fig:a}\includegraphics[width=70mm]{../Figures/error_rms_relu.png}}
\subfigure[Rms, Sigmoid]{\label{fig:b}\includegraphics[width=70mm]{../Figures/error_rms_sigmoid.png}}
\subfigure[Adam, ReLu]{\label{fig:c}\includegraphics[width=70mm]{../Figures/error_adam_relu.png}}
\subfigure[Adam, Sigmoid]{\label{fig:d}\includegraphics[width=70mm]{../Figures/error_adam_sigmoid.png}}
\subfigure[Explicit solver]{\label{fig:e}\includegraphics[width=70mm]{../Figures/error_explicit.png}}
\caption{Absolute error for NN in (a)-(d) and explicit solver in (e). NN is
trained with 20 epochs and a batch size of 30 with $(n=100)\times (m=100)$
data points of $x$
and $t$ respectively, using the analytical solution for MSE as the loss
function. The networks have three hidden layers, one of 16 neurons and two of 32.
The explicit solver in (e) is using $\Delta x=0.1$ and $\alpha=1/4$.}
\label{fig:abs_error_all}
\end{figure}



\end{document}
