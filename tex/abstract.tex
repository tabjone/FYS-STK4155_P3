\begin{abstract}                          % marks the beginning of the abstract

We looked at the mean squared error of several neural networks and an explicit
solver against a closed-form solution. We found that the neural network that
performed best was using the ReLu activation function, the RMSprop otimizer and
had 3 hidden layers. But this had a MSE of 2 orders of magnitude higher than
the explicit solver after 20 epochs. We then timed the explicit solver against a already
trained network for different matrix sizes and found that the explicit solver
was about two orders of magnitude faster than the neural network. For such a
simplistic problem a traditional solver performs better than a neural network.
\end{abstract}                            % marks the end of the abstract
